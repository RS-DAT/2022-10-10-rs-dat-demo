{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc84c549-1e95-4aec-b9fc-c56a16024600",
   "metadata": {},
   "source": [
    "# Demo: Run an esmvaltool recipe using containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e93897-8e1a-4029-a9ef-9996f8fd56cb",
   "metadata": {},
   "source": [
    "In this example, we demonstrate how to execute an ESMValtool recipe using containers on SURF's Spider infrastructure infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb6d31",
   "metadata": {},
   "source": [
    "## Prerequisite: Starting a Jupyter Server on Spider.\n",
    "\n",
    "A Jupyter Server should be started on Spider as the environment to execute this notebook. You can follow [this instruction](https://github.com/RS-DAT/JupyterDaskOnSLURM) to start a Jupyter server on Spider.\n",
    "\n",
    "After successfully setting up the Jupyter server, please copy this notebook to the Spider file system. Then open it from the browser on your local PC (as specified in the above instruction). Effectively, this notebook runs as a Slurm job on Spider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf44d734",
   "metadata": {},
   "source": [
    "## Step 1: build a Singularity container\n",
    "\n",
    "ESMValTool is provided in the form of Docker containers. Like most HPC systems, Spider supports Singularity as the container technology, according to the [documentation of Spider](https://spiderdocs.readthedocs.io/en/latest/Pages/software_on_spider.html?highlight=singularity#singularity-containers). Note that although the documentation mentions that Spider does not provide an environment for building Singularity images, one actually can convert an existing Docker image to a Singularity image, e.g. by running this command on Spider:\n",
    "\n",
    "```sh\n",
    "# Step1: build sif image (this should be done once)\n",
    "singularity build esmvaltool_stable.sif docker://esmvalgroup/esmvaltool:stable\n",
    "```\n",
    "\n",
    "This will download a Docker image from Docker Hub and build a Singularity Image File (.sif) named `esmvaltool_stable.sif` on the Spider file system, from DockerHub. Note that this may take ~20 minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc24a3",
   "metadata": {},
   "source": [
    "## Step 2: User configeration\n",
    "One can run the following command to apply user configurations for the ESMValTool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b7e268-b33f-4a54-ba1f-fec9fd8517f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 10:30:33,813 UTC [3531224] INFO    Creating folder /home/caroline-oku/.esmvaltool\n",
      "2022-09-27 10:30:33,815 UTC [3531224] INFO    Copying file /opt/conda/envs/esmvaltool/lib/python3.10/site-packages/esmvalcore/config-user.yml to path /home/caroline-oku/.esmvaltool/config-user.yml.\n",
      "2022-09-27 10:30:33,817 UTC [3531224] INFO    Copy finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get user config file\n",
    "!singularity run esmvaltool_stable.sif config get_config_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0d67b",
   "metadata": {},
   "source": [
    "## Step 3: Execute recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443bb7e-aa48-4b81-98d3-9e8cc8df23f3",
   "metadata": {},
   "source": [
    "We will execute two recipes under the folder `recipes`. Both of them plots a map of global temperature in January 2000, and plot a time series of mean annual temperature from 1850 to 2000. The difference of the two recepies are the climate datasets they use. In practice, if the dataset is huge, sequetially executing the two recipies will not be efficient. Analogous situations would be the execution of a computationally expensive recipe over a long time period, which could be split, and/or over large spatial extent at high resolution.\n",
    "\n",
    "In this example, we will demonstrate how to parallely executing the two recipies with a dask cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5f619",
   "metadata": {},
   "source": [
    "To add a Dask cluster to this notebook, you can use the Dask JupyterLab extension (look for the Dask logo on the left tab of the JupyterLab interface):\n",
    "- Click on the Dask logo;\n",
    "- click the `Scale` button, set up the number of workers to 2;\n",
    "- then click `<>` to add a code block.\n",
    "\n",
    "Then a code cell will be added to this notebook. Please drop this cell below. By executing it, a Dask SLURMCluster with 2 workers will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153b184-5877-4d7c-889a-15311698f33b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "--ADD DASK SLURMCluster HERE--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4742f29d-1432-4221-ac47-e4c5316a1b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['singularity run /home/caroline-oku/demo_singularity/demo_singularity_esmvaltool/esmvaltool_stable.sif run /home/caroline-oku/demo_singularity/demo_singularity_esmvaltool/recipes/recipe_dataset1.yml --offline=False',\n",
       " 'singularity run /home/caroline-oku/demo_singularity/demo_singularity_esmvaltool/esmvaltool_stable.sif run /home/caroline-oku/demo_singularity/demo_singularity_esmvaltool/recipes/recipe_dataset2.yml --offline=False']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the commands for execution\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path for the sif image\n",
    "sif_image = 'esmvaltool_stable.sif'\n",
    "\n",
    "# Two recipes for two datasets\n",
    "recipes = ['recipes/recipe_dataset1.yml', \n",
    "           'recipes/recipe_dataset2.yml'\n",
    "          ]\n",
    "\n",
    "# Set up shells commands\n",
    "commands = [f\"singularity run --pwd {Path.cwd()} {sif_image} run {recipe} --offline=False\" for recipe in recipes]\n",
    "commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf37b8-4f4b-4279-bc68-b03d8007f3c2",
   "metadata": {},
   "source": [
    "One can submit the commands to the Dask clusteras follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64aa907b-2c4e-4f2b-9bd3-e31936e87508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Submit the commands\n",
    "futures = client.map(os.system, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f85f72c-2c83-477c-8784-76c2b10dd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: finished, type: int, key: system-e879bb29e07bc8513966c1f2d5a62896>,\n",
       " <Future: finished, type: int, key: system-35008dcc096c451ca0fbfe5cb37433a3>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393720e-bc0c-4722-b2fb-14a82ac1ba9b",
   "metadata": {},
   "source": [
    "Once finished, one can check the downloaded climate data files and the generated results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb61df8-f2e8-4723-bc7a-96eb6840b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;33m/home/caroline-oku/climate_data/\u001b[0m\n",
      "├── \u001b[38;5;33mcmip5\u001b[0m\n",
      "│   └── \u001b[38;5;33moutput1\u001b[0m\n",
      "│       ├── \u001b[38;5;33mCCCma\u001b[0m\n",
      "│       │   └── \u001b[38;5;33mCanESM2\u001b[0m\n",
      "│       ├── \u001b[38;5;33mCNRM-CERFACS\u001b[0m\n",
      "│       │   └── \u001b[38;5;33mCNRM-CM5\u001b[0m\n",
      "│       └── \u001b[38;5;33mNSF-DOE-NCAR\u001b[0m\n",
      "│           └── \u001b[38;5;33mCESM1-CAM5\u001b[0m\n",
      "└── \u001b[38;5;33mCMIP6\u001b[0m\n",
      "    └── \u001b[38;5;33mCMIP\u001b[0m\n",
      "        └── \u001b[38;5;33mBCC\u001b[0m\n",
      "            └── \u001b[38;5;33mBCC-ESM1\u001b[0m\n",
      "\n",
      "12 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "# Check the retrived climate data\n",
    "!tree -L 4 ~/climate_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d0a804-f364-4ee8-8635-340746266bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;33m/home/caroline-oku/esmvaltool_output/\u001b[0m\n",
      "├── \u001b[38;5;33mrecipe_dataset1_20220927_103054\u001b[0m\n",
      "│   ├── index.html\n",
      "│   ├── \u001b[38;5;33mplots\u001b[0m\n",
      "│   ├── \u001b[38;5;33mrun\u001b[0m\n",
      "│   └── \u001b[38;5;33mwork\u001b[0m\n",
      "└── \u001b[38;5;33mrecipe_dataset2_20220927_103100\u001b[0m\n",
      "    ├── index.html\n",
      "    ├── \u001b[38;5;33mplots\u001b[0m\n",
      "    ├── \u001b[38;5;33mrun\u001b[0m\n",
      "    └── \u001b[38;5;33mwork\u001b[0m\n",
      "\n",
      "8 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "# Check generated results\n",
    "!tree -L 2 ~/esmvaltool_output/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "02835d5cd57458205e59899edb11fdcb9a0651fb5a52f81360dd4343685cd4f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
